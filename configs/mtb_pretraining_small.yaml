# AWS config:
aws_train_instance_type: ml.g4dn.xlarge
aws_data_input: s3://eb7-datascience/matching_the_blanks_data/
# Experiment
experiment_name: MTB-pretraining-small
# Data
data: data/cnn-small.txt #pre-training data.txt file path
normalization:
  - lowercase
  - html
  - urls
min_pool_size: 2
# Model
transformer: bert-large-uncased
# Training
batch_size: 2048 # Training batch size
max_norm: 1.0 # Clipped gradient norm
epochs: 1000 # Number of Epochs
lr: 0.00003 # learning rate
resume: False # Warm Start
save_best_model_only: True # Whether to only save the best model so far
